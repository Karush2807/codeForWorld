{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "CNN_ARCHITECTURES",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karush2807/deepLearning-openCV/blob/main/CNN_ARCHITECTURES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN ARCHITECTURES & Custom Image Dataset loader\n",
        "- we will be learning today:\n",
        "1. custom imag loader\n",
        "2. LeNet\n",
        "3. AlexNEt\n",
        "4. VGGNet"
      ],
      "metadata": {
        "id": "0w7Efocd5pAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # PyTorch library for creating and working with deep learning models\n",
        "from torch.utils.data import Dataset, DataLoader  # Tools for creating custom datasets and loading data in batches\n",
        "import pandas as pd  # Pandas library for handling and processing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "from PIL import Image"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T05:49:27.13371Z",
          "iopub.execute_input": "2025-01-02T05:49:27.133968Z",
          "iopub.status.idle": "2025-01-02T05:49:27.137919Z",
          "shell.execute_reply.started": "2025-01-02T05:49:27.133948Z",
          "shell.execute_reply": "2025-01-02T05:49:27.136943Z"
        },
        "id": "40kcYtwT5pAO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Initializes the dataset by loading image paths and their corresponding labels.\n",
        "\n",
        "        Args:\n",
        "            image_dir (str): The directory containing subdirectories of class-labeled images.\n",
        "            transform (callable, optional): Transformations to apply to images. Default is None.\n",
        "        \"\"\"\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []  # List to store image file paths\n",
        "        self.labels = []  # List to store corresponding labels\n",
        "\n",
        "        # Load all image paths and their corresponding labels\n",
        "        for label, class_dir in enumerate(os.listdir(image_dir)):\n",
        "            class_path = os.path.join(image_dir, class_dir)\n",
        "            if not os.path.isdir(class_path):  # Skip files in the directory\n",
        "                continue\n",
        "            for image_name in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_name)\n",
        "                self.image_paths.append(image_path)  # Append full image path\n",
        "                self.labels.append(label)  # Append class label (folder index)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of images in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves an image and its label by index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the desired sample.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the transformed image and its label.\n",
        "        \"\"\"\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load the image from the path and convert it to RGB format\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply transformations if any are provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:36:04.426529Z",
          "iopub.execute_input": "2025-01-02T06:36:04.426844Z",
          "iopub.status.idle": "2025-01-02T06:36:04.433684Z",
          "shell.execute_reply.started": "2025-01-02T06:36:04.426824Z",
          "shell.execute_reply": "2025-01-02T06:36:04.432496Z"
        },
        "id": "JDhSSuHw5pAQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize tensors\n",
        "])\n",
        "\n",
        "# Defining directories\n",
        "train_img_dir = 'path/to/train'\n",
        "test_img_dir = 'path/to/test'\n",
        "val_img_dir = 'path/to/val'\n",
        "\n",
        "# Creating datasets\n",
        "train_image_dataset = ImgDataset(image_dir=train_img_dir, transform=transform)\n",
        "test_image_dataset = ImgDataset(image_dir=test_img_dir, transform=transform)\n",
        "val_image_dataset = ImgDataset(image_dir=val_img_dir, transform=transform)\n",
        "\n",
        "# Checking the dataset\n",
        "print(f\"Number of training images: {len(train_image_dataset)}\")\n",
        "print(f\"Number of validation images: {len(val_image_dataset)}\")\n",
        "print(f\"Number of testing images: {len(test_image_dataset)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:45:13.627979Z",
          "iopub.execute_input": "2025-01-02T06:45:13.628301Z",
          "iopub.status.idle": "2025-01-02T06:45:15.293047Z",
          "shell.execute_reply.started": "2025-01-02T06:45:13.628273Z",
          "shell.execute_reply": "2025-01-02T06:45:15.291987Z"
        },
        "id": "l3IYoCfc5pAR",
        "outputId": "6da60772-3903-4de9-b45e-793017c88ae8"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3221505eb2fb>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Creating datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_image_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImgDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtest_image_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImgDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mval_image_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImgDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-ddd4f8d240e3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, transform)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Load all image paths and their corresponding labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mclass_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Skip files in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/train'"
          ],
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path/to/train'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "O2tixhnB5pAT"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}